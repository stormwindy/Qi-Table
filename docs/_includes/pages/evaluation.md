<h1 align="center">Evaluation</h1>
<h3 align="center">How Well Does Our System Perform?</h3>


## Evaluation Tests

### Speed and Accuracy of the Vision Module

It is vital that the vision module can run quickly because it can be called several hundred times in a complete usage cycle. 

[Insert a short description of the test and findings (possibly in table format) here]

It is even more vital that the vision module is as accurate as possible to avoid any chance of collision.

The Vision system was tested by placing eight AR markers in a 4-by-2 formations in different positions and orientations within the operation area with the elevation of 0.2m as it is the height of Infinitables prototype. 

The four pairs of markers were placed equidistant from each other and perfectly aligned. The test results’ analysis was based on comparing the angles returned for all markers and comparing the distances between the centres for each of the four pairs. In an ideal system angles should be equal for all eight markers after each trial and the distances should the same for all trials.

The standard error for each of the tests is presented in the table below. On average the standard error for computing the angle is 0.2° whereas for distance it is 0.3px.


| Test number | Standard error <br> for the **angle** (°) | Standard error <br> for the **distance** (px) |
|:-----------:|:------------------------------------:|:----------------------------------------:|
| 1 | 0.144 | 0.315 |
| 2 | 0.260 | 0.270 |
| 3 | 0.168 | 0.422 |
| 4 | 0.140 | 0.387 |
| 5 | 0.141 | 0.266 |
| 6 | 0.313 | 0.295 |
| 7 | 0.223 | 0.241 |
| 8 | 0.190 | 0.547 |
| 9 | 0.322 | 0.652 |
| 10 | 0.216 | 0.066 |
| 11 | 0.342 | 0.446 |

### Speed and Success Rate of the Path Finding Module



### User Tests

Present any user testing you have performed for your product. The same advice about presenting data should be used as above

## Main Areas of Improvement

What did you learn from your testing? How did your evaluation/user testing change your system?
